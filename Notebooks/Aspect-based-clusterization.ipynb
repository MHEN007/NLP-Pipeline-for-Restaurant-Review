{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"/kaggle/input/dataset/dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "class RestaurantTopicAnalyzer:\n",
    "    def __init__(self, similarity_threshold=0.3, device=None, embedding_model=None):\n",
    "        if device is None:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = SentenceTransformer(embedding_model, device=self.device)\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        \n",
    "        self.categories = {\n",
    "            'food': (\n",
    "                \"discussion about food quality, taste, dishes, menu items, \"\n",
    "                \"cooking, flavors, portions, ingredients, cuisine\"\n",
    "            ),\n",
    "            'place': (\n",
    "                \"discussion about restaurant ambiance, atmosphere, decoration, \"\n",
    "                \"location, cleanliness, seating, parking, venue\"\n",
    "            ),\n",
    "            'price': (\n",
    "                \"discussion about costs, prices, value for money, expenses, \"\n",
    "                \"affordability, budget, worth, deals\"\n",
    "            ),\n",
    "            'service': (\n",
    "                \"discussion about staff behavior, waiting time, customer service, \"\n",
    "                \"waiters, servers, attentiveness, hospitality\"\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        self.category_embeddings = np.array([\n",
    "            self.model.encode(description, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "            for description in self.categories.values()\n",
    "        ])\n",
    "        \n",
    "        self.kmeans = KMeans(\n",
    "            n_clusters=len(self.categories),\n",
    "            init=self.category_embeddings,\n",
    "            n_init=1\n",
    "        )\n",
    "        \n",
    "        self.cluster_to_category = {i: cat for i, cat in enumerate(self.categories.keys())}\n",
    "\n",
    "    def get_topics(self, text):\n",
    "        try:\n",
    "            text_embedding = self.model.encode(text, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "            text_embedding = text_embedding.reshape(1, -1)\n",
    "            \n",
    "            cluster = self.kmeans.predict(text_embedding)[0]\n",
    "            primary_category = self.cluster_to_category[cluster]\n",
    "            \n",
    "            similarities = {}\n",
    "            for category, description in self.categories.items():\n",
    "                cat_embedding = self.model.encode(description, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "                similarity = float(np.dot(text_embedding, cat_embedding) / \n",
    "                                (np.linalg.norm(text_embedding) * np.linalg.norm(cat_embedding)))\n",
    "                similarities[category] = similarity\n",
    "            \n",
    "            relevant_topics = {\n",
    "                category: score \n",
    "                for category, score in similarities.items() \n",
    "                if score > self.similarity_threshold\n",
    "            }\n",
    "            \n",
    "            if primary_category not in relevant_topics:\n",
    "                relevant_topics[primary_category] = similarities[primary_category]\n",
    "            \n",
    "            return relevant_topics\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text: {text}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def fit(self, texts):\n",
    "        embeddings = np.array([\n",
    "            self.model.encode(text, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "            for text in tqdm(texts, desc=\"Encoding texts\")\n",
    "        ])\n",
    "        \n",
    "        self.kmeans.fit(embeddings)\n",
    "        return self\n",
    "\n",
    "    def analyze_dataframe(self, df, text_column='text'):\n",
    "        self.fit(df[text_column].values)\n",
    "        \n",
    "        result_df = df.copy()\n",
    "        \n",
    "        for category in self.categories.keys():\n",
    "            result_df[f'topic_{category}'] = 0\n",
    "            result_df[f'score_{category}'] = 0.0\n",
    "        \n",
    "        result_df['topic_count'] = 0\n",
    "        result_df['main_topics'] = ''\n",
    "        result_df['primary_topic'] = ''\n",
    "        result_df['primary_score'] = 0.0\n",
    "        \n",
    "        print(f\"Analyzing texts on {self.device}...\")\n",
    "        for idx in tqdm(range(len(df)), desc=\"Analyzing texts\"):\n",
    "            text = str(df.iloc[idx][text_column])\n",
    "            topics = self.get_topics(text)\n",
    "            \n",
    "            for category, score in topics.items():\n",
    "                result_df.at[idx, f'topic_{category}'] = 1\n",
    "                result_df.at[idx, f'score_{category}'] = score\n",
    "            \n",
    "            result_df.at[idx, 'topic_count'] = len(topics)\n",
    "            result_df.at[idx, 'main_topics'] = ', '.join(topics.keys())\n",
    "            \n",
    "            if topics:\n",
    "                primary_topic = max(topics.items(), key=lambda x: x[1])\n",
    "                result_df.at[idx, 'primary_topic'] = primary_topic[0]\n",
    "                result_df.at[idx, 'primary_score'] = primary_topic[1]\n",
    "        \n",
    "        return result_df\n",
    "    def evaluate_clustering(self, texts):\n",
    "        embeddings = np.array([\n",
    "            self.model.encode(text, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "            for text in tqdm(texts, desc=\"Encoding texts for evaluation\")\n",
    "        ])\n",
    "        \n",
    "        self.kmeans.fit(embeddings)\n",
    "        labels = self.kmeans.labels_\n",
    "        \n",
    "        scores = {\n",
    "            'silhouette': silhouette_score(embeddings, labels),\n",
    "            'calinski_harabasz': calinski_harabasz_score(embeddings, labels),\n",
    "            'davies_bouldin': davies_bouldin_score(embeddings, labels)\n",
    "        }\n",
    "        \n",
    "        print(\"\\nClustering Evaluation Scores:\")\n",
    "        print(f\"Silhouette Score: {scores['silhouette']:.4f}\")\n",
    "        print(f\"Calinski Harabasz Score: {scores['calinski_harabasz']:.4f}\")\n",
    "        print(f\"Davies Bouldin Score: {scores['davies_bouldin']:.4f}\")\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "analyzer = RestaurantTopicAnalyzer(\n",
    "    similarity_threshold=0.3,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    embedding_model='all-MiniLM-L6-v2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_df = analyzer.analyze_dataframe(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scores = analyzer.evaluate_clustering(final_df['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_df.to_csv(\"cluster-result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluation_results = []\n",
    "models = [\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'all-mpnet-base-v2',\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'all-MiniLM-L12-v2'\n",
    "]\n",
    "thresholds = [0.2, 0.3, 0.4]\n",
    "\n",
    "for model_name in models:\n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\nProcessing model: {model_name}, with threshold: {threshold}\")\n",
    "        analyzer = RestaurantTopicAnalyzer(\n",
    "            similarity_threshold=threshold,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            embedding_model=model_name\n",
    "        )\n",
    "        \n",
    "        results_df = analyzer.analyze_dataframe(final_df)\n",
    "        \n",
    "        scores = analyzer.evaluate_clustering(final_df['text'].values)\n",
    "        scores.update({'model': model_name, 'threshold': threshold})\n",
    "        evaluation_results.append(scores)\n",
    "\n",
    "comparison_df = pd.DataFrame(evaluation_results)\n",
    "comparison_df.to_csv(\"Comparison.csv\")\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3642466,
     "sourceId": 6330015,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6249783,
     "sourceId": 10127439,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6279015,
     "sourceId": 10170466,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
