{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"./Datasets/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "food       1051\n",
       "service     506\n",
       "place       368\n",
       "price       275\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/asterisk/lib/python3.11/site-packages/transformers/utils/import_utils.py:601: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class RestaurantTopicAnalyzer:\n",
    "    def __init__(self, similarity_threshold=0.3, device=None, embedding_model=None):\n",
    "        if device is None:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = SentenceTransformer(embedding_model, device=self.device)\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        \n",
    "        self.categories = {\n",
    "            'food': (\n",
    "                \"discussion about food quality, taste, dishes, menu items, \"\n",
    "                \"cooking, flavors, portions, ingredients, cuisine\"\n",
    "            ),\n",
    "            'place': (\n",
    "                \"discussion about restaurant ambiance, atmosphere, decoration, \"\n",
    "                \"location, cleanliness, seating, parking, venue\"\n",
    "            ),\n",
    "            'price': (\n",
    "                \"discussion about costs, prices, value for money, expenses, \"\n",
    "                \"affordability, budget, worth, deals\"\n",
    "            ),\n",
    "            'service': (\n",
    "                \"discussion about staff behavior, waiting time, customer service, \"\n",
    "                \"waiters, servers, attentiveness, hospitality\"\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        self.category_embeddings = np.array([\n",
    "            self.model.encode(description, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "            for description in self.categories.values()\n",
    "        ])\n",
    "        \n",
    "        self.kmeans = KMeans(\n",
    "            n_clusters=len(self.categories),\n",
    "            init=self.category_embeddings,\n",
    "            n_init=1\n",
    "        )\n",
    "        \n",
    "        self.cluster_to_category = {i: cat for i, cat in enumerate(self.categories.keys())}\n",
    "\n",
    "    def get_topics(self, text):\n",
    "        try:\n",
    "            text_embedding = self.model.encode(text, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "            text_embedding = text_embedding.reshape(1, -1)\n",
    "            \n",
    "            cluster = self.kmeans.predict(text_embedding)[0]\n",
    "            primary_category = self.cluster_to_category[cluster]\n",
    "            \n",
    "            similarities = {}\n",
    "            for category, description in self.categories.items():\n",
    "                cat_embedding = self.model.encode(description, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "                similarity = float(np.dot(text_embedding, cat_embedding) / \n",
    "                                (np.linalg.norm(text_embedding) * np.linalg.norm(cat_embedding)))\n",
    "                similarities[category] = similarity\n",
    "            \n",
    "            relevant_topics = {\n",
    "                category: score \n",
    "                for category, score in similarities.items() \n",
    "                if score > self.similarity_threshold\n",
    "            }\n",
    "            \n",
    "            if primary_category not in relevant_topics:\n",
    "                relevant_topics[primary_category] = similarities[primary_category]\n",
    "            \n",
    "            return relevant_topics\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text: {text}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def fit(self, texts):\n",
    "        embeddings = np.array([\n",
    "            self.model.encode(text, convert_to_tensor=True, device=self.device).cpu().numpy()\n",
    "            for text in tqdm(texts, desc=\"Encoding texts\")\n",
    "        ])\n",
    "        \n",
    "        self.kmeans.fit(embeddings)\n",
    "        return self\n",
    "\n",
    "    def analyze_dataframe(self, df, text_column='text'):\n",
    "        self.fit(df[text_column].values)\n",
    "        \n",
    "        result_df = df.copy()\n",
    "        \n",
    "        for category in self.categories.keys():\n",
    "            result_df[f'topic_{category}'] = 0\n",
    "            result_df[f'score_{category}'] = 0.0\n",
    "        \n",
    "        result_df['topic_count'] = 0\n",
    "        result_df['main_topics'] = ''\n",
    "        result_df['primary_topic'] = ''\n",
    "        result_df['primary_score'] = 0.0\n",
    "        \n",
    "        print(f\"Analyzing texts on {self.device}...\")\n",
    "        for idx in tqdm(range(len(df)), desc=\"Analyzing texts\"):\n",
    "            text = str(df.iloc[idx][text_column])\n",
    "            topics = self.get_topics(text)\n",
    "            \n",
    "            for category, score in topics.items():\n",
    "                result_df.at[idx, f'topic_{category}'] = 1\n",
    "                result_df.at[idx, f'score_{category}'] = score\n",
    "            \n",
    "            result_df.at[idx, 'topic_count'] = len(topics)\n",
    "            result_df.at[idx, 'main_topics'] = ', '.join(topics.keys())\n",
    "            \n",
    "            if topics:\n",
    "                primary_topic = max(topics.items(), key=lambda x: x[1])\n",
    "                result_df.at[idx, 'primary_topic'] = primary_topic[0]\n",
    "                result_df.at[idx, 'primary_score'] = primary_topic[1]\n",
    "        \n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyzer = RestaurantTopicAnalyzer(\n",
    "    similarity_threshold=0.3,\n",
    "    device='mps' if torch.backends.mps.is_available() else 'cpu',\n",
    "    embedding_model='all-MiniLM-L6-v2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing texts on mps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2200/2200 [00:41<00:00, 52.72it/s]\n"
     ]
    }
   ],
   "source": [
    "results_df = analyzer.analyze_dataframe(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"cluster-result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: all-MiniLM-L12-v2, with threshold: 0.2\n",
      "Analyzing texts on mps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2200/2200 [00:46<00:00, 46.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to results_all-MiniLM-L12-v2_threshold_0.2.csv\n",
      "Processing model: all-MiniLM-L12-v2, with threshold: 0.3\n",
      "Analyzing texts on mps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2200/2200 [00:48<00:00, 45.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to results_all-MiniLM-L12-v2_threshold_0.3.csv\n",
      "Processing model: all-MiniLM-L12-v2, with threshold: 0.4\n",
      "Analyzing texts on mps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2200/2200 [00:46<00:00, 46.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to results_all-MiniLM-L12-v2_threshold_0.4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# models = [\n",
    "#     # 'all-MiniLM-L6-v2',\n",
    "#     # 'all-mpnet-base-v2',\n",
    "#     # 'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "#     'all-MiniLM-L12-v2'\n",
    "# ]\n",
    "# thresholds = [0.2, 0.3, 0.4]\n",
    "\n",
    "# for model_name in models:\n",
    "#     for threshold in thresholds:\n",
    "#         print(f\"Processing model: {model_name}, with threshold: {threshold}\")\n",
    "#         analyzer = RestaurantTopicAnalyzer(\n",
    "#             similarity_threshold=threshold,\n",
    "#             device='mps' if torch.backends.mps.is_available() else 'cpu',\n",
    "#             embedding_model=model_name\n",
    "#         )\n",
    "        \n",
    "#         results_df = analyzer.analyze_dataframe(final_df)\n",
    "        \n",
    "#         filename = f\"results_{model_name}_threshold_{threshold}.csv\"\n",
    "#         results_df.to_csv(filename, index=False)\n",
    "#         print(f\"Saved results to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3642466,
     "sourceId": 6330015,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6249783,
     "sourceId": 10127439,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
